# env 常规配置
# 应用名称
framework.streaming.appName=flink_ProcessKafka2redis
# 应用启动的作业类
framework.streaming.className=org.example.process.ProcessKafka2redis
# 事件流的时间属性[ProcessingTime(事件被处理时的当前系统时间，1.12前默认) EventTime(事件真实产生的时间，1.12后默认) IngestionTime(事件进入flink的时间)]
framework.streaming.timeCharacteristic=ProcessingTime
# 批流合一[STREAMING(流处理) BATCH(批处理) AUTOMATIC(自动)]
runtime.mode=STREAMING
# 是否开启checkpoint
checkpoint.open=true
# checkpoint保存路径
stateBackend.save.dir=/Users/cxm/workspace/flink_analysis/checkpoint
# 保存类型[FS(文件系统如HDFS) ROCKSOB(DB) MEMORYSTATEBACKEND(内存)]
stateBackend.type=FS
# checkpoint间隔，默认60*1000ms
checkpoint.interval=60000
# checkpoint模式[EXACTLY_ONCE(严格一次，莫扔) AT_LEAST_ONCE(至少一次)]
checkpoint.mode=EXACTLY_ONCE
# 是否使用异步快照的方式进行checkpoint,FS[默认true,false]
framework.asynchronousSnapshots=true
# 是否使用增量快照的方式进行checkpoint,ROCKSDB[默认true,false]
framework.enableIncrementalCheckpointing=true
# checkpoint最小事件间隔[默认5*1000ms，checkpoint.interval值小于该值将不生效]
checkpoint.min.pause=5000
# 发生错误时checkpoint是否失败[默认true，如果checkpoint过程失败，会导致整个应用重启]
checkpoint.fail.on.error=false

# input kafka consumer
# 可以设置多个Kakfa
# kafka1
kafka.input.brokers=127.0.0.1:9092
kafka.input.ssl=true
kafka.input.user=admin
kafka.input.pass=admin
kafka.input.topics=test
kafka.input.groupId=Group_Test
# 是否自动提交偏移量，checkpoint时也会提交偏移量
kafka.input.enable.auto.commit=true
# 自动提交偏移量的时间间隔
kafka.input.auto.commit.interval.ms=60000
# 设置事物的提交发送
kafka.input.isolation.level=read_committed
# 开启一个线程每隔一定时间检测下Kafka的分区情况
kafka.input.flink.partition-discovery.interval-millis=30000
# 当kafka中有保存偏移量从偏移量开始消费，如果没有保存偏移量则可以从最新的数据开始消费latest，最早数据开始消费earlist
kafka.input.auto.offset.reset=latest

# kafka2
kafkaTest.input.brokers=127.0.0.1:9092
kafkaTest.input.ssl=true
kafkaTest.input.user=admin
kafkaTest.input.pass=admin
kafkaTest.input.topics=test
kafkaTest.input.groupId=Group_Test
# 是否自动提交偏移量，checkpoint时也会提交偏移量
kafkaTest.input.enable.auto.commit=true
# 自动提交偏移量的时间间隔
kafkaTest.input.auto.commit.interval.ms=60000
# 设置事物的提交发送
kafkaTest.input.isolation.level=read_committed
# 开启一个线程每隔一定时间检测下Kafka的分区情况
kafkaTest.input.flink.partition-discovery.interval-millis=30000
# 当kafka中有保存偏移量从偏移量开始消费，如果没有保存偏移量则可以从最新的数据开始消费latest，最早数据开始消费earlist
kafkaTest.input.auto.offset.reset=latest

# output kafka consumer
kafka.output.brokers=127.0.0.1:9092
kafka.output.transaction.timeout=600000
kafka.output.ssl=true
kafka.output.user=admin
kafka.output.pass=admin
kafka.output.topics=test,test_out
# 单条信息最大大小10*1024*1024
kafka.output.max.request.size=10485760
# 信息压缩类型 snappy
kafka.output.compression.type=snappy
# 信息批大小 8*1024
kafka.output.batch.size=8192
# 缓存大小 64*1024*1024
kafka.output.buffer.memory=67108864

# redis
redis.nodes=127.0.0.1:8001,127.0.0.1:8002,127.0.0.1:8003,127.0.0.1:8004,127.0.0.1:8005,127.0.0.1:8006
redis.auth=123456
redis.maxRedirects=5
redis.client=flink_cluster
redis.maxTotal=5
redis.maxIdle=5
redis.minIdle=0
redis.maxWaitMillis=20000
redis.testWhileIdle=true
redis.minEvictableIdleTimeMillis=60000
redis.timeBetweenEvictionRunsMillis=30000
redis.numTestsPerEvictionRun=-1
redis.testOnBorrow=true
redis.testOnReturn=true
redis.testOnCreate=true
redis.expire=3600



